{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "\n",
    "main_folder = \"/home/omen/Documents/Nafisha/AIIMsVSdata/DICOM_GammaKnife\"\n",
    "records = []\n",
    "\n",
    "for root, dirs, files in os.walk(main_folder):\n",
    "    dicom_files = [file for file in files if file.lower().endswith(\".dcm\")]\n",
    "    \n",
    "    if dicom_files:\n",
    "        dcm_path = os.path.join(root, dicom_files[0])\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(dcm_path, stop_before_pixels=True)\n",
    "            record = {\n",
    "                \"PatientID\": getattr(dcm, \"PatientID\", \"\"),\n",
    "                \"PatientsName\": str(getattr(dcm, \"PatientName\", \"\")).replace(\"^\", \" \"),\n",
    "                \"StudyInstanceUID\": getattr(dcm, \"StudyInstanceUID\", \"\"),\n",
    "                \"StudyDate\": getattr(dcm, \"StudyDate\", \"\"),\n",
    "                \"StudyDescription\": getattr(dcm, \"StudyDescription\", \"\"),\n",
    "                \"Modality\": getattr(dcm, \"Modality\", \"\"),\n",
    "                \"SeriesDescription\": getattr(dcm, \"SeriesDescription\", \"\"),\n",
    "                \"StudyFolderPath\": root\n",
    "            }\n",
    "            records.append(record)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file: {dcm_path} due to error: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "len(np.unique(df['PatientID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_MR = df[df['Modality']=='MR']\n",
    "data_MR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78643d06",
   "metadata": {},
   "source": [
    "#### Special for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40298ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count number of unique StudyDates per PatientID\n",
    "studydate_counts = data_MR.groupby('PatientID')['StudyDate'].nunique()\n",
    "\n",
    "# Step 2: Identify PatientIDs that have >1 unique StudyDate\n",
    "valid_patients = studydate_counts[studydate_counts > 1].index\n",
    "\n",
    "# Step 3: Filter the original DataFrame to include only those patients\n",
    "filtered_data_MR = data_MR[data_MR['PatientID'].isin(valid_patients)]\n",
    "\n",
    "filtered_data_MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by PatientID and count unique StudyDescriptions\n",
    "study_counts = filtered_data_MR.groupby(\"PatientID\")[\"StudyDescription\"].nunique()\n",
    "\n",
    "# Step 2: Keep only those PatientIDs with more than one unique StudyDescription\n",
    "valid_patients = study_counts[study_counts > 1].index\n",
    "\n",
    "# Step 3: Filter the original DataFrame\n",
    "filtered_result = filtered_data_MR[filtered_data_MR[\"PatientID\"].isin(valid_patients)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396021f4",
   "metadata": {},
   "source": [
    "Below cell is to make a copy of data used for Random Forest training so that while creating a mask, original data does not get changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eff87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "new_dir = '/home/omen/Documents/Nafisha/RandomForestData/images'\n",
    "\n",
    "for idx, row in filtered_result.iterrows():\n",
    "    image_folder_path = row['StudyFolderPath']  \n",
    "    base_folder = os.path.basename(image_folder_path)\n",
    "    dest_folder = os.path.join(new_dir, base_folder)\n",
    "\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    # Copy contents of image_folder_path into dest_folder\n",
    "    for item in os.listdir(image_folder_path):\n",
    "        s = os.path.join(image_folder_path, item)\n",
    "        d = os.path.join(dest_folder, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(s, d)  # copy2 to preserve metadata\n",
    "\n",
    "    print(f\"Copied: {image_folder_path} -> {dest_folder}\")\n",
    "\n",
    "    filtered_result.at[idx, \"StudyFolderPath\"] = dest_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b200050",
   "metadata": {},
   "source": [
    "creating different folder for RTSS,RTPLAN and RTDOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Destination root folder\n",
    "rtfiles = \"/home/omen/Documents/Nafisha/RandomForestData/rtfiles\"\n",
    "\n",
    "# Filenames to move\n",
    "rt_filenames = ['RTDOSE.dcm', 'RTPLAN.dcm', 'RTSS.dcm']\n",
    "\n",
    "for idx, row in filtered_result.iterrows():\n",
    "    study_path = row['StudyFolderPath']\n",
    "    if not os.path.exists(study_path):\n",
    "        print(f\"Study folder does not exist: {study_path}\")\n",
    "        continue\n",
    "\n",
    "    # Folder name to create under rtfiles\n",
    "    folder_name = os.path.basename(study_path)\n",
    "    destination_folder = os.path.join(rtfiles, folder_name)\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    for rt_file in rt_filenames:\n",
    "        source_path = os.path.join(study_path, rt_file)\n",
    "        dest_path = os.path.join(destination_folder, rt_file)\n",
    "\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.move(source_path, dest_path)\n",
    "            print(f\"Moved: {source_path} -> {dest_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {source_path}\")\n",
    "            \n",
    "    filtered_result.at[idx, \"rtfiles\"] = destination_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f43aea",
   "metadata": {},
   "source": [
    "Generating Maks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6914a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platipy.dicom.io.rtstruct_to_nifti import convert_rtstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskfolder= \"/home/omen/Documents/Nafisha/RandomForestData/masks\"\n",
    "\n",
    "for idx, row in filtered_result.iterrows():\n",
    "    image_folder_path = row['StudyFolderPath']\n",
    "    base_folder = os.path.basename(image_folder_path)\n",
    "    mask_folder_path = os.path.join(maskfolder, base_folder)\n",
    "    rtss_path = os.path.join(row['rtfiles'], 'RTSS.dcm')\n",
    "\n",
    "    # print(os.path.exists(rtss_path))\n",
    "    \n",
    "    os.makedirs(mask_folder_path, exist_ok=True)\n",
    "    \n",
    "    convert_rtstruct(\n",
    "        dcm_img= image_folder_path,\n",
    "        dcm_rt_file = rtss_path,\n",
    "        output_dir = mask_folder_path\n",
    "    )\n",
    "    \n",
    "    filtered_result.at[idx, \"mask_folder_path\"] = mask_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73add9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ['100213278', '100480978']\n",
    "\n",
    "filtered_result = filtered_result[~filtered_result['PatientID'].isin(outliers)]\n",
    "filtered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bba521",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result[\"mask_path\"] = \"\"\n",
    "\n",
    "for idx, row in filtered_result.iterrows():\n",
    "    folder = row['mask_folder_path']\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder does not exist: {folder}\")\n",
    "        continue\n",
    "\n",
    "    # List all files in the folder\n",
    "    for file in os.listdir(folder):\n",
    "        if \"tumor\" in file.lower() and (file.endswith(\".nii\") or file.endswith(\".nii.gz\")):\n",
    "            full_path = os.path.join(folder, file)\n",
    "            print(full_path)\n",
    "            filtered_result.loc[idx, \"mask_path\"] = full_path\n",
    "            break  # stop after the first match\n",
    "\n",
    "    if filtered_result.loc[idx, \"mask_path\"] == \"\":\n",
    "        print(f\"No tumor mask found in: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b193aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "reader = sitk.ImageSeriesReader()\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prefer_t1(group):\n",
    "    # Check if any SeriesDescription contains \"t1\" (case-insensitive)\n",
    "    mask_t1 = group['SeriesDescription'].str.contains('t1', case=False, na=False)\n",
    "    if mask_t1.any():\n",
    "        # Return only rows with t1 in SeriesDescription\n",
    "        return group[mask_t1].iloc[[0]]\n",
    "    else:\n",
    "        # No t1 found, keep the first row\n",
    "        return group.iloc[[0]]\n",
    "\n",
    "new_filtered_result = filtered_result.groupby(['PatientID', 'StudyDate'], group_keys=False).apply(prefer_t1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb34703",
   "metadata": {},
   "source": [
    "# Radiomics Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiomics import featureextractor\n",
    "\n",
    "features_dict = {}\n",
    "x = []\n",
    "\n",
    "for i in range(len(weight_folders)):\n",
    "    segmentation_path = seg_paths[i]\n",
    "    segmentation_image = sitk.ReadImage(segmentation_path)\n",
    "\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(weight_folders[i])\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    image = reader.Execute()\n",
    "\n",
    "    patient_id = patient_ids[i]\n",
    "    patient_year = study_year[i]\n",
    "        \n",
    "    # print(patient_id,patient_year)\n",
    "    # print(image.GetSize(), segmentation_image.GetSize())\n",
    "    segmentation_resampled = resample_segmentation_to_image(segmentation_image, image)\n",
    "    segmentation_resampled_array = sitk.GetArrayFromImage(segmentation_resampled)\n",
    "    \n",
    "    if np.sum(segmentation_resampled_array) == 0:\n",
    "        print(f\"Warning: The resampled segmentation mask for {segmentation_path} is empty (no segmented regions found).\")\n",
    "        continue\n",
    "\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "    extractor.enableAllFeatures()\n",
    "\n",
    "    features = extractor.execute(image, segmentation_resampled)\n",
    "    \n",
    "    x.append(f\"{patient_id}_{patient_year}\")\n",
    "\n",
    "    # Store features in a list to handle repeated patient IDs\n",
    "    key = f\"{patient_id}_{patient_year}\"\n",
    "    if key in features_dict:\n",
    "        suffix = 1\n",
    "        while f\"{key}_{suffix}\" in features_dict:\n",
    "            suffix += 1\n",
    "        key = f\"{key}_{suffix}\"\n",
    "\n",
    "    if key not in features_dict:\n",
    "        features_dict[key] = []\n",
    "    features_dict[key].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_volume_feature = {}\n",
    "for key, feature_list in features_dict.items():\n",
    "    for feature in feature_list:\n",
    "        value = feature.get('original_shape_MeshVolume', None)\n",
    "        voxel_volume_feature[key] = value.item() if isinstance(value, np.ndarray) else value\n",
    "len(voxel_volume_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "for key, value in voxel_volume_feature.items():\n",
    "    parts = key.split('_')\n",
    "\n",
    "    if len(parts) > 2:\n",
    "        patient_id = parts[0]\n",
    "        year = parts[1] + \"_\" + parts[2]  # Create year_1 format\n",
    "    else:\n",
    "        patient_id, year = parts[0], parts[1]\n",
    "\n",
    "    data.append((patient_id, year, value))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Patient_ID', 'Year', 'Volume'])\n",
    "\n",
    "# Pivot the DataFrame to create a table with Patient_ID as the index, Year as columns, and Volume as the values\n",
    "volume_table = df.pivot(index='Patient_ID', columns='Year', values='Volume')\n",
    "\n",
    "# Replace missing values with \"N/A\"\n",
    "volume_table = volume_table.fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "volume_diff_column = []\n",
    "\n",
    "\n",
    "for idx, row in volume_table.iterrows():\n",
    "\n",
    "    numeric_values = pd.to_numeric(row.dropna(), errors='coerce').dropna().values\n",
    "    if len(numeric_values) > 1:\n",
    "        first_numeric = int(numeric_values[0])\n",
    "        last_numeric = int(numeric_values[-1])\n",
    "        volume_diff = last_numeric - first_numeric\n",
    "    else:\n",
    "        volume_diff = np.nan\n",
    "\n",
    "\n",
    "    volume_diff_column.append(volume_diff)\n",
    "\n",
    "# Add the calculated 'volume_diff' as a new column\n",
    "volume_table['volume_diff'] = volume_diff_column\n",
    "\n",
    "# Create a new column based on whether the volume_diff is positive or negative\n",
    "volume_table['change'] = volume_table['volume_diff'].apply(lambda x: 'increased' if x > 0 else 'not increased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['original_shape_MajorAxisLength',\n",
    " 'original_shape_Maximum2DDiameterRow',\n",
    " 'original_shape_Maximum3DDiameter',\n",
    " 'original_firstorder_Kurtosis',\n",
    " 'original_glcm_MCC',\n",
    " 'original_gldm_GrayLevelNonUniformity',\n",
    " 'original_glrlm_GrayLevelNonUniformity',\n",
    " 'original_glrlm_RunLengthNonUniformity',\n",
    " 'original_ngtdm_Busyness',\n",
    " 'original_ngtdm_Coarseness']\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5603c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_names:\n",
    "    volume_table[feature] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in volume_table.iterrows():\n",
    "    numeric_values = pd.to_numeric(row.dropna(), errors='coerce').dropna()\n",
    "    if numeric_values.empty:\n",
    "        continue\n",
    "\n",
    "    year = min(numeric_values.index.tolist())  # earliest available year\n",
    "    dict_key = f\"{idx}_{year}\"\n",
    "\n",
    "    # Check if the key exists in features_dict\n",
    "    if dict_key in features_dict:\n",
    "        feature_values = features_dict[dict_key][0]\n",
    "        for feature in feature_names:\n",
    "            volume_table.at[idx, feature] = feature_values[feature]\n",
    "    else:\n",
    "        print(f\"Warning: {dict_key} not found in features_dict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_table = volume_table.loc[:, ~volume_table.columns.str.match(r'^\\d+$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_table.drop(columns=['volume_diff'], inplace=True)\n",
    "volume_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d61279",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_table['change'] = volume_table['change'].map({'increased': 1, 'not increased': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/omen/Documents/Nafisha/RandomForestData/radiomicsFeat.csv'\n",
    "volume_table.to_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
